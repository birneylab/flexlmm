# birneylab/flexlmm: Output

## Introduction

This document describes the output produced by the pipeline.

The directories listed below will be created in the results directory after the pipeline has finished. All paths are relative to the top-level results directory.

## Pipeline overview

The pipeline is built using [Nextflow](https://www.nextflow.io/) and processes data using the following steps:

- [Relatedness](#grm) - Computes full-genome and LOCO relatedness matrices
- [Variance components](#reml) - Estimate genetic and residuals variances
- [Fit model](#fit) - Compute _p_-values and other SNP-wise statistics
- [Plots](#plots) - Plots of association results, _p_-value distributions, and relatedness matrices
- [Pipeline information](#pipeline-information) - Report metrics generated during the workflow execution

### Relatedness

Computation of the genetic relatedness matrices for the full genome and with each chromosome left out (LOCO).

<details markdown="1">
<summary>Output files</summary>

- `relatedness_matrix/`
  - `loco/{left_out_chromosome_name}`: relatedness matrix evaluated on the full genome except for the named chromosome
    - `*.rel.bin`: [binary plink format](https://www.cog-genomics.org/plink/2.0/distance)
    - `*.rel.id`: sample IDs
  - `full_genome/*.cram`: relatedness matrix evaluated on the full genome
    - `*.rel.bin`: [binary plink format](https://www.cog-genomics.org/plink/2.0/distance)
    - `*.rel.id`: sample IDs

</details>

### Stitch

Raw output from the STITCH imputation per chromosome.
Read about [STITCH](https://github.com/rwdavies/STITCH) to know more about the various files produced.

<details markdown="1">
<summary>Output files</summary>

- `{group}/stitch/chromosome_*`
  - `plots/`: Plots produced by STITCH
  - `RData/`: Intermediate STITCH results as R objects
  - `chromosome_*.vcf.gz`: Imputed VCF file for the chromosome
  - `chromosome_*.vcf.gz.csi`: Index file for the VCF

</details>

### Joint output

Full-genome imputation output

<details markdown="1">
<summary>Output files</summary>

- `{group}/joint_stitch_output`
  - `vcf/joint_stitch_output.vcf.gz`: Full genome imputed genotypes
  - `vcf/joint_stitch_output.vcf.gz.csi`: VCF index
  - `anndata/joint_stitch_output.anndata.zarr`: Full genome imputed genotypes in anndata format

</details>

### Performance

Imputation performance per SNP according to different metrics. The summary file has the following columns:

```
chr,pos,ref,alt,info_score,pearson_r
```

The `pearson_r` column is present only if `ground_truth_vcf` is set.

<details markdown="1">
<summary>Output files</summary>

- `{group}/performance_summaries`
  - `joint_stitch_output.performance.csv.gz`: CSV file containing the imputation performance results
- `imputation_quality_plots`
  - `*.pdf`: Plots produced in R with ggplot2 and cowplot showing the cumulative density of the different performance metrics, group by iteration/parameter combination in the respective workflows

</details>

### Pipeline information

<details markdown="1">
<summary>Output files</summary>

- `pipeline_info/`
  - Reports generated by Nextflow: `execution_report.html`, `execution_timeline.html`, `execution_trace.txt` and `pipeline_dag.dot`/`pipeline_dag.svg`.
  - Reports generated by the pipeline: `pipeline_report.html`, `pipeline_report.txt` and `software_versions.yml`. The `pipeline_report*` files will only be present if the `--email` / `--email_on_fail` parameter's are used when running the pipeline.
  - Reformatted samplesheet files used as input to the pipeline: `samplesheet.valid.csv`.

</details>

[Nextflow](https://www.nextflow.io/docs/latest/tracing.html) provides excellent functionality for generating various reports relevant to the running and execution of the pipeline. This will allow you to troubleshoot errors with the running of the pipeline, and also provide you with other information such as launch commands, run times and resource usage.

## Note on anndata, scikit-allel, and zarr

[Zarr](https://zarr.dev/) is a format for the storage of large multidimensional arrays.
Combined with [Dask](https://www.dask.org/), zarr allows to operate on larger-than-memory matrices.
[Anndata](https://anndata.readthedocs.io/en/latest/) is a Python package that provides an annotated data matrix. It can use zarr as a storage format and Dask for certain computations.
Internally the pipeline uses [scikit-allel](https://scikit-allel.readthedocs.io/en/stable/) to convert VCF files to the zarr format, and then with a custom script it converts the scikit-allel output to an anndata object that is serialised to the zarr format. This enormously simplifies data manipulations and minimises the chance for errors.

Since the zarr anndata objects are produced by the pipeline in any case, I also save them as outputs for further exploration and for interfacing with other pipelines (e.g. GWAS pipeline).
