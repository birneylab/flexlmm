# birneylab/flexlmm: Output

## Introduction

This document describes the output produced by the pipeline.

The directories listed below will be created in the results directory after the pipeline has finished. All paths are relative to the top-level results directory.

## Pipeline overview

The pipeline is built using [Nextflow](https://www.nextflow.io/) and processes data using the following steps:

- [Relatedness](#relatedness) - Computes full-genome and LOCO relatedness matrices
- [Variance components](#variance) - Estimate genetic and residuals variances
- [Fit model](#fit) - Compute _p_-values and other SNP-wise statistics
- [Plots](#plots) - Plots of association results, _p_-value distributions, and relatedness matrices
- [Pipeline information](#pipeline-information) - Report metrics generated during the workflow execution

### Relatedness

Computation of the genetic relatedness matrices for the full genome and with each chromosome left out (LOCO).

<details markdown="1">
<summary>Output files</summary>

- `relatedness_matrix/`
  - `loco/{left_out_chromosome_name}`: relatedness matrix evaluated on the full genome except for the named chromosome
    - `*.rel.bin`: [binary plink format](https://www.cog-genomics.org/plink/2.0/distance)
    - `*.rel.id`: sample IDs
  - `full_genome/`: relatedness matrix evaluated on the full genome
    - `*.rel.bin`: [binary plink format](https://www.cog-genomics.org/plink/2.0/distance)
    - `*.rel.id`: sample IDs

</details>

### Variance components

Estimates of the genetic and enviromental variances for each LOCO relatedness matrix and each phenotype. Can also be used to estimate heritability. RDS objects that can be loaded into R using the `loadRDS` function. They contain the whole object retured by the call to `gaston::lmm.aireml`.

<details markdown="1">
<summary>Output files</summary>

- `variance_components/{phenotype_name}/*.hsq.rds`

</details>

### Fit model

GWAS result as compressed tab-separated file with header line, one file for each chromosome and phenotype.
Columns are:

<details markdown="1">
<summary>Format description</summary>

- `chr`: chromosome name
- `pos`: position of the variant
- `ref`: reference allele
- `alt`: alternate allele
- `lrt_chisq`: $\chi^2$ value of the Likelihood-ratio test
- `lrt_df`: degrees of freedom of the Likelihood-ratio test (number of extra parameters in the real model compared to the null model)
- `lrt_p`: _p_-value computed from `lrt_chisq` and `lrt_df`
- `beta`: fixed effect sizes for all the terms (including intercept and covariates)
  - This column contains several values. For each parameter, it contains the string `variable_name~beta_value`. This is separated by commas from other variable_name-beta_value pairs. Example of the content of the `beta` column for one line: `var1~0.3,var2~0.6,(Intercept)~2,x~1.2,x==1TRUE~0.9`

</details>

<details markdown="1">
<summary>Output files</summary>

- `gwas/{phenotype_name}/*.gwas.tsv.gz`

</details>

### Performance

Imputation performance per SNP according to different metrics. The summary file has the following columns:

```
chr,pos,ref,alt,info_score,pearson_r
```

The `pearson_r` column is present only if `ground_truth_vcf` is set.

<details markdown="1">
<summary>Output files</summary>

- `{group}/performance_summaries`
  - `joint_stitch_output.performance.csv.gz`: CSV file containing the imputation performance results
- `imputation_quality_plots`
  - `*.pdf`: Plots produced in R with ggplot2 and cowplot showing the cumulative density of the different performance metrics, group by iteration/parameter combination in the respective workflows

</details>

### Pipeline information

<details markdown="1">
<summary>Output files</summary>

- `pipeline_info/`
  - Reports generated by Nextflow: `execution_report.html`, `execution_timeline.html`, `execution_trace.txt` and `pipeline_dag.dot`/`pipeline_dag.svg`.
  - Reports generated by the pipeline: `pipeline_report.html`, `pipeline_report.txt` and `software_versions.yml`. The `pipeline_report*` files will only be present if the `--email` / `--email_on_fail` parameter's are used when running the pipeline.
  - Reformatted samplesheet files used as input to the pipeline: `samplesheet.valid.csv`.

</details>

[Nextflow](https://www.nextflow.io/docs/latest/tracing.html) provides excellent functionality for generating various reports relevant to the running and execution of the pipeline. This will allow you to troubleshoot errors with the running of the pipeline, and also provide you with other information such as launch commands, run times and resource usage.

## Note on anndata, scikit-allel, and zarr

[Zarr](https://zarr.dev/) is a format for the storage of large multidimensional arrays.
Combined with [Dask](https://www.dask.org/), zarr allows to operate on larger-than-memory matrices.
[Anndata](https://anndata.readthedocs.io/en/latest/) is a Python package that provides an annotated data matrix. It can use zarr as a storage format and Dask for certain computations.
Internally the pipeline uses [scikit-allel](https://scikit-allel.readthedocs.io/en/stable/) to convert VCF files to the zarr format, and then with a custom script it converts the scikit-allel output to an anndata object that is serialised to the zarr format. This enormously simplifies data manipulations and minimises the chance for errors.

Since the zarr anndata objects are produced by the pipeline in any case, I also save them as outputs for further exploration and for interfacing with other pipelines (e.g. GWAS pipeline).
